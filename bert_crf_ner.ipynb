{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 全局参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T09:06:29.381007Z",
     "iopub.status.idle": "2024-11-19T09:06:29.390589Z",
     "shell.execute_reply": "2024-11-19T09:06:29.389496Z",
     "shell.execute_reply.started": "2024-11-19T09:06:29.380979Z"
    }
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 128  # 每条数据最大长度\n",
    "BATCH_SIZE = 8  # 批处理大小\n",
    "NUM_LABELS = 3  # NER标记数量 (e.g., B-LOC, I-LOC, O, etc.)\n",
    "MODEL_NAME = 'bert-base-chinese'  # 模型名称\n",
    "# MODEL_PATH = 'model/'  # 模型路径\n",
    "MODEL_PATH = r'E:/JupyterLab//LLM//Large-Model//bert//'  # 模型路径\n",
    "LABEL_DATA_PATH = 'data/label_data.json'  # 标注数据路径\n",
    "OUT_DIR = 'model/'  # 输出路径\n",
    "LOG_DIR = 'log/'  # 日志路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T09:06:29.392557Z",
     "iopub.status.busy": "2024-11-19T09:06:29.392199Z",
     "iopub.status.idle": "2024-11-19T09:06:29.397763Z",
     "shell.execute_reply": "2024-11-19T09:06:29.396547Z",
     "shell.execute_reply.started": "2024-11-19T09:06:29.392527Z"
    }
   },
   "outputs": [],
   "source": [
    "label_list = ['O','B-PLACE','I-PLACE']  # 根据你自己的标记集合进行修改\n",
    "id2label = {\n",
    "    i: label for i,label in enumerate(label_list)\n",
    "}\n",
    "label2id = {\n",
    "    label: i for i,label in enumerate(label_list)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T09:06:29.399794Z",
     "iopub.status.busy": "2024-11-19T09:06:29.399236Z",
     "iopub.status.idle": "2024-11-19T09:06:29.411228Z",
     "shell.execute_reply": "2024-11-19T09:06:29.410132Z",
     "shell.execute_reply.started": "2024-11-19T09:06:29.399746Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'O', 1: 'B-PLACE', 2: 'I-PLACE'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T09:06:29.427442Z",
     "iopub.status.busy": "2024-11-19T09:06:29.427117Z",
     "iopub.status.idle": "2024-11-19T09:06:29.432960Z",
     "shell.execute_reply": "2024-11-19T09:06:29.431897Z",
     "shell.execute_reply.started": "2024-11-19T09:06:29.427414Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'O': 0, 'B-PLACE': 1, 'I-PLACE': 2}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label2id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T09:06:29.436306Z",
     "iopub.status.busy": "2024-11-19T09:06:29.435974Z",
     "iopub.status.idle": "2024-11-19T09:06:30.434850Z",
     "shell.execute_reply": "2024-11-19T09:06:30.434141Z",
     "shell.execute_reply.started": "2024-11-19T09:06:29.436278Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset, DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T09:06:30.438930Z",
     "iopub.status.busy": "2024-11-19T09:06:30.438733Z",
     "iopub.status.idle": "2024-11-19T09:06:30.449944Z",
     "shell.execute_reply": "2024-11-19T09:06:30.449283Z",
     "shell.execute_reply.started": "2024-11-19T09:06:30.438909Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texts: ['拜登总统对国会两院联席会议发表讲话', '中国政府中东问题特使翟隽出席金砖国家中东事务副外长/特使磋商']\n",
      "Labels: [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 2, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "# 来自标注好的JSON文件\n",
    "with open(LABEL_DATA_PATH, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "texts = []\n",
    "labels = []\n",
    "\n",
    "for entry in data:\n",
    "    text = entry['content']\n",
    "    label_sequence = ['O'] * len(text)  # 初始化所有字符的标签为 'O'\n",
    "\n",
    "    for tag in entry['tags']:\n",
    "        if tag['name'] == 'PLACE':\n",
    "            start = tag['start']\n",
    "            end = tag['end']\n",
    "\n",
    "            # 将开始位置标记为 'B-PLACE'\n",
    "            label_sequence[start] = 'B-PLACE'\n",
    "\n",
    "            # 将后续位置标记为 'I-PLACE'\n",
    "            for i in range(start + 1, end):\n",
    "                label_sequence[i] = 'I-PLACE'\n",
    "\n",
    "    # 将标签转换为标签索引\n",
    "    label_indices = [label2id[label] for label in label_sequence]\n",
    "\n",
    "    texts.append(text)\n",
    "    labels.append(label_indices)\n",
    "\n",
    "# 检查转换后的格式\n",
    "print(\"Texts:\", texts[-2:])\n",
    "print(\"Labels:\", labels[-2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T09:06:30.450709Z",
     "iopub.status.busy": "2024-11-19T09:06:30.450526Z",
     "iopub.status.idle": "2024-11-19T09:06:30.455718Z",
     "shell.execute_reply": "2024-11-19T09:06:30.455075Z",
     "shell.execute_reply.started": "2024-11-19T09:06:30.450690Z"
    }
   },
   "outputs": [],
   "source": [
    "# 划分数据集--训练测试和验证\n",
    "texts_train, texts_temp, labels_train, labels_temp = train_test_split(\n",
    "    texts, labels, test_size=0.2, random_state=42\n",
    ")\n",
    "texts_val, texts_test, labels_val, labels_test = train_test_split(\n",
    "    texts_temp, labels_temp, test_size=0.5, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T09:06:30.456570Z",
     "iopub.status.busy": "2024-11-19T09:06:30.456385Z",
     "iopub.status.idle": "2024-11-19T09:06:30.461436Z",
     "shell.execute_reply": "2024-11-19T09:06:30.460887Z",
     "shell.execute_reply.started": "2024-11-19T09:06:30.456551Z"
    }
   },
   "outputs": [],
   "source": [
    "# 构造字典形式的数据\n",
    "def create_dataset(texts, labels):\n",
    "    ids = list(range(len(texts)))\n",
    "    tokens_list = [list(text) for text in texts]\n",
    "    return {'id': ids, 'tokens': tokens_list, 'ner_tags': labels}\n",
    "\n",
    "train_data = create_dataset(texts_train, labels_train)\n",
    "val_data = create_dataset(texts_val, labels_val)\n",
    "test_data = create_dataset(texts_test, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T09:06:30.490090Z",
     "iopub.status.busy": "2024-11-19T09:06:30.489798Z",
     "iopub.status.idle": "2024-11-19T09:06:30.511792Z",
     "shell.execute_reply": "2024-11-19T09:06:30.511245Z",
     "shell.execute_reply.started": "2024-11-19T09:06:30.490068Z"
    }
   },
   "outputs": [],
   "source": [
    "# 创建 Dataset 和 DatasetDict\n",
    "train_dataset = Dataset.from_dict(train_data)\n",
    "val_dataset = Dataset.from_dict(val_data)\n",
    "test_dataset = Dataset.from_dict(test_data)\n",
    "\n",
    "ner_data = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'validation': val_dataset,\n",
    "    'test': test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T09:06:30.687147Z",
     "iopub.status.busy": "2024-11-19T09:06:30.686411Z",
     "iopub.status.idle": "2024-11-19T09:06:30.692636Z",
     "shell.execute_reply": "2024-11-19T09:06:30.691501Z",
     "shell.execute_reply.started": "2024-11-19T09:06:30.687123Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'tokens', 'ner_tags'],\n",
       "        num_rows: 305\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'tokens', 'ner_tags'],\n",
       "        num_rows: 38\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'tokens', 'ner_tags'],\n",
       "        num_rows: 39\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T09:06:30.880319Z",
     "iopub.status.busy": "2024-11-19T09:06:30.879365Z",
     "iopub.status.idle": "2024-11-19T09:06:30.889726Z",
     "shell.execute_reply": "2024-11-19T09:06:30.888593Z",
     "shell.execute_reply.started": "2024-11-19T09:06:30.880267Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 0,\n",
       " 'tokens': ['美',\n",
       "  '国',\n",
       "  '宣',\n",
       "  '布',\n",
       "  '向',\n",
       "  '加',\n",
       "  '沙',\n",
       "  '及',\n",
       "  '该',\n",
       "  '地',\n",
       "  '区',\n",
       "  '的',\n",
       "  '巴',\n",
       "  '勒',\n",
       "  '斯',\n",
       "  '坦',\n",
       "  '平',\n",
       "  '民',\n",
       "  '提',\n",
       "  '供',\n",
       "  '更',\n",
       "  '多',\n",
       "  '人',\n",
       "  '道',\n",
       "  '主',\n",
       "  '义',\n",
       "  '援',\n",
       "  '助'],\n",
       " 'ner_tags': [1,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_data['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T09:06:31.616927Z",
     "iopub.status.busy": "2024-11-19T09:06:31.615885Z",
     "iopub.status.idle": "2024-11-19T09:06:33.096302Z",
     "shell.execute_reply": "2024-11-19T09:06:33.095337Z",
     "shell.execute_reply.started": "2024-11-19T09:06:31.616874Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T09:06:33.098043Z",
     "iopub.status.busy": "2024-11-19T09:06:33.097738Z",
     "iopub.status.idle": "2024-11-19T09:06:33.147647Z",
     "shell.execute_reply": "2024-11-19T09:06:33.146805Z",
     "shell.execute_reply.started": "2024-11-19T09:06:33.098022Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='E:/JupyterLab//LLM//Large-Model//bert//bert-base-chinese', vocab_size=21128, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained(MODEL_PATH+MODEL_NAME)  # 自己下载的中文 BERT 模型\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T09:06:33.148810Z",
     "iopub.status.busy": "2024-11-19T09:06:33.148521Z",
     "iopub.status.idle": "2024-11-19T09:06:33.154558Z",
     "shell.execute_reply": "2024-11-19T09:06:33.153758Z",
     "shell.execute_reply.started": "2024-11-19T09:06:33.148790Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58ecc8551d814eadb1db9a9b05c0c422",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/305 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3fb2190ac094a6e8a11aeff127aa2d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/38 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dfef29b70a840a693113c27dcd04b96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/39 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess_function(examples):\n",
    "    # 对输入的 tokens 进行分词和编码\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples['tokens'], \n",
    "        truncation=True, \n",
    "        padding=True, \n",
    "        is_split_into_words=True\n",
    "    )\n",
    "\n",
    "    # 处理 NER 标签与分词后的对齐问题\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples['ner_tags']):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)  # 获取分词后单词的索引\n",
    "        previous_word_idx = None  # 上一个单词的索引\n",
    "        label_ids = []\n",
    "\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:  # 如果是特殊标记（如[CLS], [SEP], [PAD]）\n",
    "                label_ids.append(-100)  # 设置为忽略值\n",
    "            elif word_idx != previous_word_idx:  # 如果是新单词\n",
    "                label_ids.append(label[word_idx])  # 使用原始标签\n",
    "            else:  # 如果是同一单词的子词\n",
    "                label_ids.append(-100)  # 设置为忽略值\n",
    "            previous_word_idx = word_idx  # 更新上一个单词索引\n",
    "\n",
    "        labels.append(label_ids)\n",
    "    \n",
    "    # 将处理后的标签添加到分词结果中\n",
    "    tokenized_inputs['labels'] = labels\n",
    "\n",
    "    return tokenized_inputs\n",
    "\n",
    "# 应用预处理函数到数据集\n",
    "tokenized_datasets = ner_data.map(preprocess_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T09:06:34.207791Z",
     "iopub.status.busy": "2024-11-19T09:06:34.207059Z",
     "iopub.status.idle": "2024-11-19T09:06:34.218545Z",
     "shell.execute_reply": "2024-11-19T09:06:34.217368Z",
     "shell.execute_reply.started": "2024-11-19T09:06:34.207753Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 0,\n",
       " 'tokens': ['美',\n",
       "  '国',\n",
       "  '宣',\n",
       "  '布',\n",
       "  '向',\n",
       "  '加',\n",
       "  '沙',\n",
       "  '及',\n",
       "  '该',\n",
       "  '地',\n",
       "  '区',\n",
       "  '的',\n",
       "  '巴',\n",
       "  '勒',\n",
       "  '斯',\n",
       "  '坦',\n",
       "  '平',\n",
       "  '民',\n",
       "  '提',\n",
       "  '供',\n",
       "  '更',\n",
       "  '多',\n",
       "  '人',\n",
       "  '道',\n",
       "  '主',\n",
       "  '义',\n",
       "  '援',\n",
       "  '助'],\n",
       " 'ner_tags': [1,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'input_ids': [101,\n",
       "  5401,\n",
       "  1744,\n",
       "  2146,\n",
       "  2357,\n",
       "  1403,\n",
       "  1217,\n",
       "  3763,\n",
       "  1350,\n",
       "  6421,\n",
       "  1765,\n",
       "  1277,\n",
       "  4638,\n",
       "  2349,\n",
       "  1239,\n",
       "  3172,\n",
       "  1788,\n",
       "  2398,\n",
       "  3696,\n",
       "  2990,\n",
       "  897,\n",
       "  3291,\n",
       "  1914,\n",
       "  782,\n",
       "  6887,\n",
       "  712,\n",
       "  721,\n",
       "  3001,\n",
       "  1221,\n",
       "  102,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'token_type_ids': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'labels': [-100,\n",
       "  1,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T09:06:34.865674Z",
     "iopub.status.busy": "2024-11-19T09:06:34.864681Z",
     "iopub.status.idle": "2024-11-19T09:06:35.741734Z",
     "shell.execute_reply": "2024-11-19T09:06:35.740789Z",
     "shell.execute_reply.started": "2024-11-19T09:06:34.865620Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertModel, BertPreTrainedModel\n",
    "from crf import CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTCRF(BertPreTrainedModel):\n",
    "    def __init__(self, config, num_tags=None):\n",
    "        super(BERTCRF, self).__init__(config)\n",
    "        self.bert = BertModel(config)\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "\n",
    "        self.word_embeds = 768  # BERT hidden size\n",
    "        self.num_tags = num_tags\n",
    "\n",
    "        self.classifier = nn.Linear(self.word_embeds, self.num_tags)\n",
    "        self.crf = CRF(num_tags=self.num_tags, batch_first=True)\n",
    "\n",
    "        # 使用BERT的权重初始化方法\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids=None, attention_mask=None, labels=None):\n",
    "        # BERT模型输出\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        sequence_output = outputs[0]  # [batch_size, seq_len, hidden_size]\n",
    "        sequence_output = self.dropout(sequence_output)\n",
    "        logits = self.classifier(sequence_output)\n",
    "        outputs = (logits,)\n",
    "\n",
    "        # 如果提供了标签，计算CRF的损失\n",
    "        if labels is not None:\n",
    "            loss = self.crf(emissions=logits, tags=labels, mask=attention_mask)\n",
    "            outputs = (-1*loss,) + outputs  # 损失是负的，因为我们希望最小化损失\n",
    "\n",
    "        return outputs  # 返回（损失，logits）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T09:06:35.751682Z",
     "iopub.status.busy": "2024-11-19T09:06:35.751472Z",
     "iopub.status.idle": "2024-11-19T09:06:36.359175Z",
     "shell.execute_reply": "2024-11-19T09:06:36.357967Z",
     "shell.execute_reply.started": "2024-11-19T09:06:35.751661Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BERTCRF were not initialized from the model checkpoint at E:/JupyterLab//LLM//Large-Model//bert//bert-base-chinese and are newly initialized: ['classifier.bias', 'classifier.weight', 'crf.end_transitions', 'crf.start_transitions', 'crf.transitions']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# 初始化模型\n",
    "model = BERTCRF.from_pretrained(MODEL_PATH+MODEL_NAME, NUM_LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T09:06:36.361453Z",
     "iopub.status.busy": "2024-11-19T09:06:36.361067Z",
     "iopub.status.idle": "2024-11-19T09:06:36.389382Z",
     "shell.execute_reply": "2024-11-19T09:06:36.388497Z",
     "shell.execute_reply.started": "2024-11-19T09:06:36.361430Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "from torch.optim import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T09:06:36.619080Z",
     "iopub.status.busy": "2024-11-19T09:06:36.618750Z",
     "iopub.status.idle": "2024-11-19T09:06:36.628825Z",
     "shell.execute_reply": "2024-11-19T09:06:36.627671Z",
     "shell.execute_reply.started": "2024-11-19T09:06:36.619058Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_ner_metrics(true_labels, pred_labels):\n",
    "    \"\"\"\n",
    "    自定义评估函数，输入为二维列表，输出为各指标\n",
    "    \"\"\"\n",
    "    assert len(true_labels) == len(pred_labels), \"true_labels 和 pred_labels 的长度必须一致\"\n",
    "    \n",
    "    # 初始化统计变量\n",
    "    total_true = 0  # 总的真实实体数\n",
    "    total_pred = 0  # 总的预测实体数\n",
    "    total_correct = 0  # 预测正确的实体数\n",
    "    total_tokens = 0  # 总的标注的token数\n",
    "    correct_tokens = 0  # 预测正确的token数\n",
    "    \n",
    "    # 遍历每个序列\n",
    "    for true_seq, pred_seq in zip(true_labels, pred_labels):\n",
    "        assert len(true_seq) == len(pred_seq), \"每个序列的长度必须一致\"\n",
    "        \n",
    "        for true, pred in zip(true_seq, pred_seq):\n",
    "            # 统计 token-level 准确性\n",
    "            total_tokens += 1\n",
    "            if true == pred:\n",
    "                correct_tokens += 1\n",
    "            \n",
    "            # 如果是实体标签，更新统计\n",
    "            if true != \"O\":  # 真实标签为实体\n",
    "                total_true += 1\n",
    "                if true == pred:  # 预测正确的实体\n",
    "                    total_correct += 1\n",
    "            \n",
    "            if pred != \"O\":  # 预测标签为实体\n",
    "                total_pred += 1\n",
    "    \n",
    "    # 计算指标\n",
    "    accuracy = correct_tokens / total_tokens if total_tokens > 0 else 0.0\n",
    "    precision = total_correct / total_pred if total_pred > 0 else 0.0\n",
    "    recall = total_correct / total_true if total_true > 0 else 0.0\n",
    "    f1 = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "    \n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    pred_logits, labels = pred\n",
    "    pred_logits = pred_logits.argmax(-1)\n",
    "    # 取去除 padding 的部分\n",
    "    predictions = [\n",
    "        [id2label[eval_preds] for (eval_preds, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(pred_logits, labels)\n",
    "    ]\n",
    "\n",
    "    true_labels = [\n",
    "        [id2label[l] for (eval_preds, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(pred_logits, labels)\n",
    "   ]\n",
    "    result = calculate_ner_metrics(\n",
    "        true_labels,\n",
    "        predictions\n",
    "    )\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T09:06:37.497242Z",
     "iopub.status.busy": "2024-11-19T09:06:37.496128Z",
     "iopub.status.idle": "2024-11-19T09:06:37.614202Z",
     "shell.execute_reply": "2024-11-19T09:06:37.612987Z",
     "shell.execute_reply.started": "2024-11-19T09:06:37.497186Z"
    }
   },
   "outputs": [],
   "source": [
    "# 重写 Trainer 类\n",
    "class CustomTrainer(Trainer):\n",
    "    def create_optimizer(self):\n",
    "        if self.optimizer is None:\n",
    "            # 获取模型参数\n",
    "            decay_parameters = [\n",
    "                p for n, p in self.model.named_parameters() if n.endswith(\"weight\")\n",
    "            ]\n",
    "            no_decay_parameters = [\n",
    "                p for n, p in self.model.named_parameters() if n.endswith(\"bias\")\n",
    "            ]\n",
    "            # 将参数分组\n",
    "            optimizer_grouped_parameters = [\n",
    "                {\"params\": decay_parameters, \"weight_decay\": self.args.weight_decay},\n",
    "                {\"params\": no_decay_parameters, \"weight_decay\": 0.0},\n",
    "            ]\n",
    "            # 使用 AdamW 作为优化器\n",
    "            self.optimizer = AdamW(\n",
    "                optimizer_grouped_parameters, lr=self.args.learning_rate\n",
    "            )\n",
    "        return self.optimizer\n",
    "\n",
    "\n",
    "# 创建训练参数\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUT_DIR,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    logging_dir=LOG_DIR,\n",
    "    save_total_limit=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T09:06:38.072437Z",
     "iopub.status.busy": "2024-11-19T09:06:38.071443Z",
     "iopub.status.idle": "2024-11-19T09:06:38.077693Z",
     "shell.execute_reply": "2024-11-19T09:06:38.076486Z",
     "shell.execute_reply.started": "2024-11-19T09:06:38.072383Z"
    }
   },
   "outputs": [],
   "source": [
    "# 数据收集器，用于将数据转换为ner可接受的格式\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T09:06:38.973147Z",
     "iopub.status.busy": "2024-11-19T09:06:38.972111Z",
     "iopub.status.idle": "2024-11-19T09:06:39.266938Z",
     "shell.execute_reply": "2024-11-19T09:06:39.265972Z",
     "shell.execute_reply.started": "2024-11-19T09:06:38.973093Z"
    }
   },
   "outputs": [],
   "source": [
    "# 定义 Trainer\n",
    "trainer = CustomTrainer(\n",
    "    model=model,  # 替换为你的模型\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['validation'],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T09:06:56.918883Z",
     "iopub.status.busy": "2024-11-19T09:06:56.918387Z",
     "iopub.status.idle": "2024-11-19T09:06:56.927024Z",
     "shell.execute_reply": "2024-11-19T09:06:56.925775Z",
     "shell.execute_reply.started": "2024-11-19T09:06:56.918859Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BERTCRF(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       "  (crf): CRF(num_tags=3)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T09:06:59.405520Z",
     "iopub.status.busy": "2024-11-19T09:06:59.404843Z",
     "iopub.status.idle": "2024-11-19T09:07:01.112018Z",
     "shell.execute_reply": "2024-11-19T09:07:01.110809Z",
     "shell.execute_reply.started": "2024-11-19T09:06:59.405466Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b53c9bc7108f46808b337a07178f2076",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/117 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\envs\\py311\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:440: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "c:\\Users\\15499\\Documents\\GitHub\\chinese_ner_place\\crf.py:237: UserWarning: where received a uint8 condition tensor. This behavior is deprecated and will be removed in a future version of PyTorch. Use a boolean condition instead. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorCompare.cpp:530.)\n",
      "  score = torch.where(mask[i].unsqueeze(1), next_score, score)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55fed06dd47241c1a399997264086141",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0242048501968384, 'eval_accuracy': 0.990990990990991, 'eval_precision': 0.9900497512437811, 'eval_recall': 0.9660194174757282, 'eval_f1_score': 0.977886977886978, 'eval_runtime': 0.2226, 'eval_samples_per_second': 170.739, 'eval_steps_per_second': 22.466, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3df6a785a8794eae84f4860b23e468f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4407471716403961, 'eval_accuracy': 0.991991991991992, 'eval_precision': 0.9712918660287081, 'eval_recall': 0.9854368932038835, 'eval_f1_score': 0.9783132530120482, 'eval_runtime': 0.2009, 'eval_samples_per_second': 189.123, 'eval_steps_per_second': 24.885, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9bdad31de084b8981c24363fd720372",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7782583832740784, 'eval_accuracy': 0.992992992992993, 'eval_precision': 0.9805825242718447, 'eval_recall': 0.9805825242718447, 'eval_f1_score': 0.9805825242718447, 'eval_runtime': 0.2191, 'eval_samples_per_second': 173.408, 'eval_steps_per_second': 22.817, 'epoch': 3.0}\n",
      "{'train_runtime': 28.6383, 'train_samples_per_second': 31.95, 'train_steps_per_second': 4.085, 'train_loss': 2.547114967280983, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=117, training_loss=2.547114967280983, metrics={'train_runtime': 28.6383, 'train_samples_per_second': 31.95, 'train_steps_per_second': 4.085, 'total_flos': 31034027498760.0, 'train_loss': 2.547114967280983, 'epoch': 3.0})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 训练 model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T08:17:45.058370Z",
     "iopub.status.busy": "2024-11-19T08:17:45.057797Z",
     "iopub.status.idle": "2024-11-19T08:17:45.063345Z",
     "shell.execute_reply": "2024-11-19T08:17:45.062571Z",
     "shell.execute_reply.started": "2024-11-19T08:17:45.058349Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model/checkpoint-78'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_ckpt_path = trainer.state.best_model_checkpoint\n",
    "best_ckpt_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T08:18:35.309711Z",
     "iopub.status.busy": "2024-11-19T08:18:35.309055Z",
     "iopub.status.idle": "2024-11-19T08:18:35.520661Z",
     "shell.execute_reply": "2024-11-19T08:18:35.519495Z",
     "shell.execute_reply.started": "2024-11-19T08:18:35.309656Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f9dd82a59364470be468220b3f9df3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.4621560573577881,\n",
       " 'eval_accuracy': 0.9962013295346629,\n",
       " 'eval_precision': 0.9880952380952381,\n",
       " 'eval_recall': 0.9880952380952381,\n",
       " 'eval_f1_score': 0.9880952380952381,\n",
       " 'eval_runtime': 0.1972,\n",
       " 'eval_samples_per_second': 197.767,\n",
       " 'eval_steps_per_second': 25.355,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(eval_dataset=tokenized_datasets['test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T08:27:10.144699Z",
     "iopub.status.busy": "2024-11-19T08:27:10.144123Z",
     "iopub.status.idle": "2024-11-19T08:27:10.156436Z",
     "shell.execute_reply": "2024-11-19T08:27:10.155045Z",
     "shell.execute_reply.started": "2024-11-19T08:27:10.144644Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'今天，美利坚合众国国防部发言人乔治说中华人民共和国的歼20战机很优秀。'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试文本\n",
    "input_text = \"今天，美利坚合众国国防部发言人乔治说中华人民共和国的歼20战机很优秀。\"\n",
    "encoding = tokenizer(input_text, return_tensors=\"pt\", is_split_into_words=False, truncation=True)\n",
    "encoding = {k: v.to(model.device) for k, v in encoding.items()}\n",
    "input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T08:25:14.959061Z",
     "iopub.status.busy": "2024-11-19T08:25:14.957891Z",
     "iopub.status.idle": "2024-11-19T08:25:14.995914Z",
     "shell.execute_reply": "2024-11-19T08:25:14.994703Z",
     "shell.execute_reply.started": "2024-11-19T08:25:14.959003Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入文本: 今天，美利坚合众国国防部发言人乔治说中华人民共和国的歼20战机很优秀。\n",
      "预测结果:\n",
      "[CLS]           -> O\n",
      "今               -> O\n",
      "天               -> O\n",
      "，               -> O\n",
      "美               -> B-PLACE\n",
      "利               -> I-PLACE\n",
      "坚               -> I-PLACE\n",
      "合               -> I-PLACE\n",
      "众               -> I-PLACE\n",
      "国               -> I-PLACE\n",
      "国               -> O\n",
      "防               -> O\n",
      "部               -> O\n",
      "发               -> O\n",
      "言               -> O\n",
      "人               -> O\n",
      "乔               -> O\n",
      "治               -> O\n",
      "说               -> O\n",
      "中               -> B-PLACE\n",
      "华               -> I-PLACE\n",
      "人               -> I-PLACE\n",
      "民               -> I-PLACE\n",
      "共               -> I-PLACE\n",
      "和               -> I-PLACE\n",
      "国               -> I-PLACE\n",
      "的               -> O\n",
      "歼               -> O\n",
      "20              -> O\n",
      "战               -> O\n",
      "机               -> O\n",
      "很               -> O\n",
      "优               -> O\n",
      "秀               -> O\n",
      "。               -> O\n",
      "[SEP]           -> O\n"
     ]
    }
   ],
   "source": [
    "# 模型预测\n",
    "with torch.no_grad():\n",
    "    outputs = model(**encoding)  # 获得模型的输出\n",
    "    logits = outputs[0]  # 获取logits，维度: [batch_size, seq_len, num_tags]\n",
    "\n",
    "    # 通过 CRF 层来获取最佳路径标签（最可能的标签序列）\n",
    "    predicted_class_ids = model.crf.decode(logits, mask=encoding['attention_mask'])  # 预测标签\n",
    "    predicted_class_ids = predicted_class_ids.squeeze().tolist()  # 把预测的 class ids 转换成列表\n",
    "\n",
    "\n",
    "# 将预测结果映射为标签，并将标签与原始文本对应起来\n",
    "predicted_labels = [id2label[class_id] for class_id in predicted_class_ids]\n",
    "tokens = tokenizer.convert_ids_to_tokens(encoding[\"input_ids\"].squeeze().tolist())\n",
    "results = list(zip(tokens, predicted_labels))\n",
    "\n",
    "# 打印预测结果\n",
    "print(\"输入文本:\", input_text)\n",
    "print(\"预测结果:\")\n",
    "for token, label in results:\n",
    "    print(f\"{token:15} -> {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用Fine-tuning模型预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from transformers import BertModel, BertTokenizer, BertPreTrainedModel\n",
    "from crf import CRF\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTCRF(BertPreTrainedModel):\n",
    "    def __init__(self, config, num_tags=None):\n",
    "        super(BERTCRF, self).__init__(config)\n",
    "        self.bert = BertModel(config)\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "\n",
    "        self.word_embeds = 768  # BERT hidden size\n",
    "        self.num_tags = num_tags\n",
    "\n",
    "        self.classifier = nn.Linear(self.word_embeds, self.num_tags)\n",
    "        self.crf = CRF(num_tags=self.num_tags, batch_first=True)\n",
    "\n",
    "        # 使用BERT的权重初始化方法\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids=None, attention_mask=None, labels=None):\n",
    "        # BERT模型输出\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        sequence_output = outputs[0]  # [batch_size, seq_len, hidden_size]\n",
    "        sequence_output = self.dropout(sequence_output)\n",
    "        logits = self.classifier(sequence_output)\n",
    "        outputs = (logits,)\n",
    "\n",
    "        # 如果提供了标签，计算CRF的损失\n",
    "        if labels is not None:\n",
    "            loss = self.crf(emissions=logits, tags=labels, mask=attention_mask)\n",
    "            outputs = (-loss,) + outputs  # 损失是负的，因为我们希望最小化损失\n",
    "\n",
    "        return outputs  # 返回（损失，logits）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 记载训练好的模型\n",
    "best_ckpt_path = 'model/checkpoint-78'\n",
    "model = BERTCRF.from_pretrained(best_ckpt_path, num_tags=3)  # 需要自己输出标签数量\n",
    "tokenizer = BertTokenizer.from_pretrained(best_ckpt_path)  # 使用与训练时相同的 tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设需要预测的文本在一个 DataFrame 中\n",
    "texts = [\n",
    "    '中国政府中东问题特使翟隽会见伊拉克驻华大使赛义德',\n",
    "    '外交部阿富汗事务特使岳晓勇会见联合国秘书长阿富汗问题独立评估特别协调员',\n",
    "    '中国政府中东问题特使翟隽会见巴林外交次大臣阿卜杜拉',\n",
    "    '多哥总理多贝会见中国外交部非洲司司长吴鹏',\n",
    "    '国务卿安东尼·布林肯（Antony J. Blinken）在切萨皮克湾基金会（Chesapeake Bay Foundation）发表讲话： “应对危机，抓住时机：发挥美国在全球气候问题上的领导作用”',\n",
    "    '外交部亚非司司长王镝访问中东六国并赴俄罗斯举行中俄中东事务司局级磋商',\n",
    "    '美国对印太地区的持久承诺：本届政府印太战略发布两周年',\n",
    "    '关于被非法关押的美国人和俄罗斯政治犯获释的声明',\n",
    "    '中国政府非洲事务特别代表许镜湖访问纳米比亚',\n",
    "]\n",
    "df = pd.DataFrame(data={'text':texts})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {\n",
    "    0: 'O',\n",
    "    1: 'B-PLACE',\n",
    "    2: 'I-PLACE'\n",
    "}\n",
    "\n",
    "def predict(texts):\n",
    "    model.eval()  \n",
    "    predictions = []\n",
    "\n",
    "    for input_text in texts:\n",
    "        encoding = tokenizer(input_text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "        encoding = {k: v.to(model.device) for k, v in encoding.items()}\n",
    "\n",
    "        # 模型预测\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**encoding)  # 获得模型的输出\n",
    "            logits = outputs[0]  # 获取logits，维度: [batch_size, seq_len, num_tags]\n",
    "\n",
    "            # 通过 CRF 层来获取最佳路径标签（最可能的标签序列）\n",
    "            predicted_class_ids = model.crf.decode(logits, mask=encoding['attention_mask'])  # 预测标签\n",
    "            predicted_class_ids = predicted_class_ids.squeeze().tolist()  # 把预测的 class ids 转换成列表\n",
    "\n",
    "        # 将预测结果映射为标签\n",
    "        predicted_labels = [id2label[class_id] for class_id in predicted_class_ids[1:-1]]  # 去掉 [CLS] 和 [SEP] 标签\n",
    "        predictions.append(predicted_labels)\n",
    "\n",
    "    return predictions\n",
    "\n",
    "# 执行预测\n",
    "df['predictions'] = predict(df['text'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>中国政府中东问题特使翟隽会见伊拉克驻华大使赛义德</td>\n",
       "      <td>[B-PLACE, I-PLACE, O, O, B-PLACE, I-PLACE, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>外交部阿富汗事务特使岳晓勇会见联合国秘书长阿富汗问题独立评估特别协调员</td>\n",
       "      <td>[O, O, O, B-PLACE, I-PLACE, I-PLACE, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>中国政府中东问题特使翟隽会见巴林外交次大臣阿卜杜拉</td>\n",
       "      <td>[B-PLACE, I-PLACE, O, O, B-PLACE, I-PLACE, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>多哥总理多贝会见中国外交部非洲司司长吴鹏</td>\n",
       "      <td>[B-PLACE, I-PLACE, O, O, O, O, O, O, B-PLACE, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>国务卿安东尼·布林肯（Antony J. Blinken）在切萨皮克湾基金会（Chesape...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>外交部亚非司司长王镝访问中东六国并赴俄罗斯举行中俄中东事务司局级磋商</td>\n",
       "      <td>[O, O, O, B-PLACE, I-PLACE, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>美国对印太地区的持久承诺：本届政府印太战略发布两周年</td>\n",
       "      <td>[B-PLACE, I-PLACE, O, B-PLACE, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>关于被非法关押的美国人和俄罗斯政治犯获释的声明</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, B-PLACE, I-PLACE, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>中国政府非洲事务特别代表许镜湖访问纳米比亚</td>\n",
       "      <td>[B-PLACE, I-PLACE, O, O, B-PLACE, I-PLACE, O, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0                           中国政府中东问题特使翟隽会见伊拉克驻华大使赛义德   \n",
       "1                外交部阿富汗事务特使岳晓勇会见联合国秘书长阿富汗问题独立评估特别协调员   \n",
       "2                          中国政府中东问题特使翟隽会见巴林外交次大臣阿卜杜拉   \n",
       "3                               多哥总理多贝会见中国外交部非洲司司长吴鹏   \n",
       "4  国务卿安东尼·布林肯（Antony J. Blinken）在切萨皮克湾基金会（Chesape...   \n",
       "5                 外交部亚非司司长王镝访问中东六国并赴俄罗斯举行中俄中东事务司局级磋商   \n",
       "6                         美国对印太地区的持久承诺：本届政府印太战略发布两周年   \n",
       "7                            关于被非法关押的美国人和俄罗斯政治犯获释的声明   \n",
       "8                              中国政府非洲事务特别代表许镜湖访问纳米比亚   \n",
       "\n",
       "                                         predictions  \n",
       "0  [B-PLACE, I-PLACE, O, O, B-PLACE, I-PLACE, O, ...  \n",
       "1  [O, O, O, B-PLACE, I-PLACE, I-PLACE, O, O, O, ...  \n",
       "2  [B-PLACE, I-PLACE, O, O, B-PLACE, I-PLACE, O, ...  \n",
       "3  [B-PLACE, I-PLACE, O, O, O, O, O, O, B-PLACE, ...  \n",
       "4  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "5  [O, O, O, B-PLACE, I-PLACE, O, O, O, O, O, O, ...  \n",
       "6  [B-PLACE, I-PLACE, O, B-PLACE, O, O, O, O, O, ...  \n",
       "7  [O, O, O, O, O, O, O, O, B-PLACE, I-PLACE, O, ...  \n",
       "8  [B-PLACE, I-PLACE, O, O, B-PLACE, I-PLACE, O, ...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: 中国政府中东问题特使翟隽会见伊拉克驻华大使赛义德\n",
      "Predicted Labels:\n",
      "中               -> B-PLACE\n",
      "国               -> I-PLACE\n",
      "政               -> O\n",
      "府               -> O\n",
      "中               -> B-PLACE\n",
      "东               -> I-PLACE\n",
      "问               -> O\n",
      "题               -> O\n",
      "特               -> O\n",
      "使               -> O\n",
      "翟               -> O\n",
      "隽               -> O\n",
      "会               -> O\n",
      "见               -> O\n",
      "伊               -> B-PLACE\n",
      "拉               -> I-PLACE\n",
      "克               -> I-PLACE\n",
      "驻               -> O\n",
      "华               -> O\n",
      "大               -> O\n",
      "使               -> O\n",
      "赛               -> O\n",
      "义               -> O\n",
      "德               -> O\n",
      "\n",
      "\n",
      "Text: 外交部阿富汗事务特使岳晓勇会见联合国秘书长阿富汗问题独立评估特别协调员\n",
      "Predicted Labels:\n",
      "外               -> O\n",
      "交               -> O\n",
      "部               -> O\n",
      "阿               -> B-PLACE\n",
      "富               -> I-PLACE\n",
      "汗               -> I-PLACE\n",
      "事               -> O\n",
      "务               -> O\n",
      "特               -> O\n",
      "使               -> O\n",
      "岳               -> O\n",
      "晓               -> O\n",
      "勇               -> O\n",
      "会               -> O\n",
      "见               -> O\n",
      "联               -> O\n",
      "合               -> O\n",
      "国               -> O\n",
      "秘               -> O\n",
      "书               -> O\n",
      "长               -> O\n",
      "阿               -> B-PLACE\n",
      "富               -> I-PLACE\n",
      "汗               -> I-PLACE\n",
      "问               -> O\n",
      "题               -> O\n",
      "独               -> O\n",
      "立               -> O\n",
      "评               -> O\n",
      "估               -> O\n",
      "特               -> O\n",
      "别               -> O\n",
      "协               -> O\n",
      "调               -> O\n",
      "员               -> O\n",
      "\n",
      "\n",
      "Text: 中国政府中东问题特使翟隽会见巴林外交次大臣阿卜杜拉\n",
      "Predicted Labels:\n",
      "中               -> B-PLACE\n",
      "国               -> I-PLACE\n",
      "政               -> O\n",
      "府               -> O\n",
      "中               -> B-PLACE\n",
      "东               -> I-PLACE\n",
      "问               -> O\n",
      "题               -> O\n",
      "特               -> O\n",
      "使               -> O\n",
      "翟               -> O\n",
      "隽               -> O\n",
      "会               -> O\n",
      "见               -> O\n",
      "巴               -> B-PLACE\n",
      "林               -> I-PLACE\n",
      "外               -> O\n",
      "交               -> O\n",
      "次               -> O\n",
      "大               -> O\n",
      "臣               -> O\n",
      "阿               -> O\n",
      "卜               -> O\n",
      "杜               -> O\n",
      "拉               -> O\n",
      "\n",
      "\n",
      "Text: 多哥总理多贝会见中国外交部非洲司司长吴鹏\n",
      "Predicted Labels:\n",
      "多               -> B-PLACE\n",
      "哥               -> I-PLACE\n",
      "总               -> O\n",
      "理               -> O\n",
      "多               -> O\n",
      "贝               -> O\n",
      "会               -> O\n",
      "见               -> O\n",
      "中               -> B-PLACE\n",
      "国               -> I-PLACE\n",
      "外               -> O\n",
      "交               -> O\n",
      "部               -> O\n",
      "非               -> B-PLACE\n",
      "洲               -> I-PLACE\n",
      "司               -> O\n",
      "司               -> O\n",
      "长               -> O\n",
      "吴               -> O\n",
      "鹏               -> O\n",
      "\n",
      "\n",
      "Text: 国务卿安东尼·布林肯（Antony J. Blinken）在切萨皮克湾基金会（Chesapeake Bay Foundation）发表讲话： “应对危机，抓住时机：发挥美国在全球气候问题上的领导作用”\n",
      "Predicted Labels:\n",
      "国               -> O\n",
      "务               -> O\n",
      "卿               -> O\n",
      "安               -> O\n",
      "东               -> O\n",
      "尼               -> O\n",
      "·               -> O\n",
      "布               -> O\n",
      "林               -> O\n",
      "肯               -> O\n",
      "（               -> O\n",
      "[UNK]           -> O\n",
      "[UNK]           -> O\n",
      ".               -> O\n",
      "[UNK]           -> O\n",
      "）               -> O\n",
      "在               -> O\n",
      "切               -> B-PLACE\n",
      "萨               -> I-PLACE\n",
      "皮               -> I-PLACE\n",
      "克               -> I-PLACE\n",
      "湾               -> O\n",
      "基               -> O\n",
      "金               -> O\n",
      "会               -> O\n",
      "（               -> O\n",
      "[UNK]           -> O\n",
      "[UNK]           -> O\n",
      "[UNK]           -> O\n",
      "）               -> O\n",
      "发               -> O\n",
      "表               -> O\n",
      "讲               -> O\n",
      "话               -> O\n",
      "：               -> O\n",
      "[UNK]           -> O\n",
      "应               -> O\n",
      "对               -> O\n",
      "危               -> O\n",
      "机               -> O\n",
      "，               -> O\n",
      "抓               -> O\n",
      "住               -> O\n",
      "时               -> O\n",
      "机               -> O\n",
      "：               -> O\n",
      "发               -> O\n",
      "挥               -> O\n",
      "美               -> B-PLACE\n",
      "国               -> I-PLACE\n",
      "在               -> O\n",
      "全               -> O\n",
      "球               -> O\n",
      "气               -> O\n",
      "候               -> O\n",
      "问               -> O\n",
      "题               -> O\n",
      "上               -> O\n",
      "的               -> O\n",
      "领               -> O\n",
      "导               -> O\n",
      "作               -> O\n",
      "用               -> O\n",
      "[UNK]           -> O\n",
      "\n",
      "\n",
      "Text: 外交部亚非司司长王镝访问中东六国并赴俄罗斯举行中俄中东事务司局级磋商\n",
      "Predicted Labels:\n",
      "外               -> O\n",
      "交               -> O\n",
      "部               -> O\n",
      "亚               -> B-PLACE\n",
      "非               -> I-PLACE\n",
      "司               -> O\n",
      "司               -> O\n",
      "长               -> O\n",
      "王               -> O\n",
      "[UNK]           -> O\n",
      "访               -> O\n",
      "问               -> O\n",
      "中               -> B-PLACE\n",
      "东               -> I-PLACE\n",
      "六               -> O\n",
      "国               -> I-PLACE\n",
      "并               -> O\n",
      "赴               -> O\n",
      "俄               -> B-PLACE\n",
      "罗               -> I-PLACE\n",
      "斯               -> I-PLACE\n",
      "举               -> O\n",
      "行               -> O\n",
      "中               -> B-PLACE\n",
      "俄               -> I-PLACE\n",
      "中               -> B-PLACE\n",
      "东               -> I-PLACE\n",
      "事               -> O\n",
      "务               -> O\n",
      "司               -> O\n",
      "局               -> O\n",
      "级               -> O\n",
      "磋               -> O\n",
      "商               -> O\n",
      "\n",
      "\n",
      "Text: 美国对印太地区的持久承诺：本届政府印太战略发布两周年\n",
      "Predicted Labels:\n",
      "美               -> B-PLACE\n",
      "国               -> I-PLACE\n",
      "对               -> O\n",
      "印               -> B-PLACE\n",
      "太               -> O\n",
      "地               -> O\n",
      "区               -> O\n",
      "的               -> O\n",
      "持               -> O\n",
      "久               -> O\n",
      "承               -> O\n",
      "诺               -> O\n",
      "：               -> O\n",
      "本               -> O\n",
      "届               -> O\n",
      "政               -> O\n",
      "府               -> O\n",
      "印               -> O\n",
      "太               -> O\n",
      "战               -> O\n",
      "略               -> O\n",
      "发               -> O\n",
      "布               -> O\n",
      "两               -> O\n",
      "周               -> O\n",
      "年               -> O\n",
      "\n",
      "\n",
      "Text: 关于被非法关押的美国人和俄罗斯政治犯获释的声明\n",
      "Predicted Labels:\n",
      "关               -> O\n",
      "于               -> O\n",
      "被               -> O\n",
      "非               -> O\n",
      "法               -> O\n",
      "关               -> O\n",
      "押               -> O\n",
      "的               -> O\n",
      "美               -> B-PLACE\n",
      "国               -> I-PLACE\n",
      "人               -> O\n",
      "和               -> O\n",
      "俄               -> B-PLACE\n",
      "罗               -> I-PLACE\n",
      "斯               -> I-PLACE\n",
      "政               -> O\n",
      "治               -> O\n",
      "犯               -> O\n",
      "获               -> O\n",
      "释               -> O\n",
      "的               -> O\n",
      "声               -> O\n",
      "明               -> O\n",
      "\n",
      "\n",
      "Text: 中国政府非洲事务特别代表许镜湖访问纳米比亚\n",
      "Predicted Labels:\n",
      "中               -> B-PLACE\n",
      "国               -> I-PLACE\n",
      "政               -> O\n",
      "府               -> O\n",
      "非               -> B-PLACE\n",
      "洲               -> I-PLACE\n",
      "事               -> O\n",
      "务               -> O\n",
      "特               -> O\n",
      "别               -> O\n",
      "代               -> O\n",
      "表               -> O\n",
      "许               -> O\n",
      "镜               -> O\n",
      "湖               -> O\n",
      "访               -> O\n",
      "问               -> O\n",
      "纳               -> B-PLACE\n",
      "米               -> I-PLACE\n",
      "比               -> I-PLACE\n",
      "亚               -> I-PLACE\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 打印预测结果\n",
    "for i, text in enumerate(df['text']):\n",
    "    print(f\"Text: {text}\")\n",
    "    print(\"Predicted Labels:\")\n",
    "    for token, label in zip(tokenizer.tokenize(text), df.loc[i,'predictions']):\n",
    "        print(f\"{token:15} -> {label}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
